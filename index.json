[{"authors":["admin"],"categories":null,"content":"I am a Master’s student in the Computer Science department at University of California, San Diego working with Prof. Jingbo Shang. I completed my Bachelor Of Technology in Computer Science And Engineering from the Indian Institute of Technology, Kanpur in 2017. I am broadly interested in Natural Language Processing, Text mining and Graph mining. My current research revolves around developing principled data-driven approaches with light human effort. I worked as a Data Scientist and Product Engineer at Sprinklr for 2 years and I interned at Microsoft India in the summer of 2016.\nApart from Academics, I enjoy spending time playing Lawn Tennis, Table Tennis, Badminton. I watch football(soccer) and I rarely write too. Checkout my blog!\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dheeraj7596.github.io/author/dheeraj-mekala/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dheeraj-mekala/","section":"authors","summary":"I am a Master’s student in the Computer Science department at University of California, San Diego working with Prof. Jingbo Shang. I completed my Bachelor Of Technology in Computer Science And Engineering from the Indian Institute of Technology, Kanpur in 2017.","tags":null,"title":"Dheeraj Mekala","type":"authors"},{"authors":["Dheeraj Mekala","Jingbo Shang"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"8d08b4d40973ce39b689e8b6008f4b35","permalink":"https://dheeraj7596.github.io/publication/conwea/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/publication/conwea/","section":"publication","summary":"Weakly supervised text classification based on a few user-provided seed words has recently attracted much attention from researchers. Existing methods mainly generate pseudo-labels in a context-free manner (e.g., string matching), therefore, the ambiguous, context-dependent nature of human language has been long overlooked. In this paper, we propose a novel framework ConWea, providing contextualized weak supervision for text classification. Specifically, we leverage contextualized representations of word occurrences and seed word information to automatically differentiate multiple interpretations of the same word, and thus create a contextualized corpus. This contextualized corpus is further utilized to train the classifier and expand seed words in an iterative manner. This process not only adds new contextualized, highly label-indicative keywords but also disambiguates initial seed words, making our weak supervision fully contextualized. Extensive experiments and case studies on real-world datasets demonstrate the necessity and significant advantages of using contextualized weak supervision, especially when the class labels are fine-grained.","tags":null,"title":"Contextualized Weak Supervision for Text Classification","type":"publication"},{"authors":["Rahul Wadbude","Vivek Gupta","Dheeraj Mekala","Harish Karnick"],"categories":null,"content":"","date":1515283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515283200,"objectID":"3106506114df20382093264727ae04e9","permalink":"https://dheeraj7596.github.io/publication/ubr/","publishdate":"2018-01-07T00:00:00Z","relpermalink":"/publication/ubr/","section":"publication","summary":"Review score prediction of text reviews has recently gained a lot of attention in recommendation systems. A major problem in models for review score prediction is the presence of noise due to user-bias in review scores. We propose two simple statistical methods to remove such noise and improve review score prediction. Compared to other methods that use multiple classifiers, one for each user, our model uses a single global classifier to predict review scores. We empirically evaluate our methods on two major categories (Electronics and Movies and TV) of the SNAP published Amazon e-Commerce Reviews data-set and Amazon Fine Food reviews data-set. We obtain improved review score prediction for three commonly used text feature representations.","tags":null,"title":"User Bias Removal in Review Score Prediction","type":"publication"},{"authors":["Dheeraj Mekala","Vivek Gupta","Bhargavi Paranjape","Harish Karnick"],"categories":null,"content":"","date":1504742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504742400,"objectID":"f4fca25bad8544c7a9afffeabfb7cc69","permalink":"https://dheeraj7596.github.io/publication/scdv/","publishdate":"2017-09-07T00:00:00Z","relpermalink":"/publication/scdv/","section":"publication","summary":"We present a feature vector formation technique for documents - Sparse Composite Document Vector (SCDV) which overcomes several shortcomings of the current distributional paragraph vector representations that are widely used for text representation. In SCDV, word embeddings are clustered to capture multiple semantic contexts in which words occur. They are then chained together to form document topic-vectors that can express complex, multi-topic documents. Through extensive experiments on multi-class and multi-label classification tasks, we outperform the previous state-of-the-art method, NTSG (Liu et al., 2015a). We also show that SCDV embeddings perform well on heterogeneous tasks like Topic Coherence, context-sensitive Learning and Information Retrieval. Moreover, we achieve significant reduction in training and prediction times compared to other representation methods. SCDV achieves best of both worlds - better performance with lower time and space complexity","tags":null,"title":"SCDV : Sparse Composite Document Vectors using soft clustering over distributional representations","type":"publication"},{"authors":["Dheeraj Mekala","Vivek Gupta","Purushottam Kar","Harish Karnick"],"categories":null,"content":"","date":1494115200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494115200,"objectID":"1e6410e36bf161434bd2326d47453b6f","permalink":"https://dheeraj7596.github.io/publication/bopt/","publishdate":"2017-05-07T00:00:00Z","relpermalink":"/publication/bopt/","section":"publication","summary":"Hierarchical classification is supervised multi-class classification problem over the set of class labels organized according to a hierarchy. In this project, we study the work by Ramaswamy et al. on hierarchical classification over symmetric tree distance loss. We extend the consistency of hierarchical classification algorithm over asymmetric tree distance loss. We design a O(nk log n) algorithm to find bayes optimal classification for a k-ary tree as hierarchy. We show that under reasonable assumptions over asymmetric loss function, the Bayes optimal classification over this asymmetric loss can be found in O(k log n). We exploit this insight and attempt to extend the Ova-Cascade algorithm Ramaswamy et al. for hierarchical classification over asymmetric loss","tags":null,"title":"Bayes-optimal Hierarchical Classification over Asymmetric Tree-Distance Loss","type":"publication"}]